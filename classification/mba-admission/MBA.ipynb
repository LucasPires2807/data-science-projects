{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some of our data and how it is shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>international</th>\n",
       "      <th>gpa</th>\n",
       "      <th>major</th>\n",
       "      <th>race</th>\n",
       "      <th>gmat</th>\n",
       "      <th>work_exp</th>\n",
       "      <th>work_industry</th>\n",
       "      <th>admission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "      <td>3.30</td>\n",
       "      <td>Business</td>\n",
       "      <td>Asian</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.28</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>Black</td>\n",
       "      <td>680.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Investment Management</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>True</td>\n",
       "      <td>3.30</td>\n",
       "      <td>Business</td>\n",
       "      <td>NaN</td>\n",
       "      <td>710.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.47</td>\n",
       "      <td>STEM</td>\n",
       "      <td>Black</td>\n",
       "      <td>690.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Technology</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.35</td>\n",
       "      <td>STEM</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>590.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   application_id  gender  international   gpa       major      race   gmat  \\\n",
       "0               1  Female          False  3.30    Business     Asian  620.0   \n",
       "1               2    Male          False  3.28  Humanities     Black  680.0   \n",
       "2               3  Female           True  3.30    Business       NaN  710.0   \n",
       "3               4    Male          False  3.47        STEM     Black  690.0   \n",
       "4               5    Male          False  3.35        STEM  Hispanic  590.0   \n",
       "\n",
       "   work_exp          work_industry admission  \n",
       "0       3.0     Financial Services     Admit  \n",
       "1       5.0  Investment Management       NaN  \n",
       "2       5.0             Technology     Admit  \n",
       "3       6.0             Technology       NaN  \n",
       "4       5.0             Consulting       NaN  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('MBA.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6194 entries, 0 to 6193\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   application_id  6194 non-null   int64  \n",
      " 1   gender          6194 non-null   object \n",
      " 2   international   6194 non-null   bool   \n",
      " 3   gpa             6194 non-null   float64\n",
      " 4   major           6194 non-null   object \n",
      " 5   race            4352 non-null   object \n",
      " 6   gmat            6194 non-null   float64\n",
      " 7   work_exp        6194 non-null   float64\n",
      " 8   work_industry   6194 non-null   object \n",
      " 9   admission       1000 non-null   object \n",
      "dtypes: bool(1), float64(3), int64(1), object(5)\n",
      "memory usage: 441.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the unique values of categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': array(['Female', 'Male'], dtype=object),\n",
       " 'major': array(['Business', 'Humanities', 'STEM'], dtype=object),\n",
       " 'race': array(['Asian', 'Black', nan, 'Hispanic', 'White', 'Other'], dtype=object),\n",
       " 'work_industry': array(['Financial Services', 'Investment Management', 'Technology',\n",
       "        'Consulting', 'Nonprofit/Gov', 'PE/VC', 'Health Care',\n",
       "        'Investment Banking', 'Other', 'Retail', 'Energy', 'CPG',\n",
       "        'Real Estate', 'Media/Entertainment'], dtype=object)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values_for_col = {}\n",
    "for col in ['gender', 'major', 'race', 'work_industry']:\n",
    "    unique_values_for_col.update({col: df[col].unique()})\n",
    "unique_values_for_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is an already unbalance of some of the races given by the dataset\n",
    "\n",
    "Considering that it is almost half missing, lets make some imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race\n",
       "White       1456\n",
       "Asian       1147\n",
       "Black        916\n",
       "Hispanic     596\n",
       "Other        237\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_race = df['race'].value_counts(normalize=True)\n",
    "missing_mask = df['race'].isnull()\n",
    "df.loc[missing_mask, 'race'] = np.random.choice(\n",
    "    probability_race.index,\n",
    "    size=missing_mask.sum(),\n",
    "    p=probability_race.values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since at the description of the dataset it says that NA values in admission means that the admission was denied, let's impute 'Deny' at the missing values so that we can use supervised machine learning techniques to predict if a certain candidate will have it's admission status as 'Admit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(5194)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['admission'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['admission'] = df['admission'].fillna('Deny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6194 entries, 0 to 6193\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   application_id  6194 non-null   int64  \n",
      " 1   gender          6194 non-null   object \n",
      " 2   international   6194 non-null   bool   \n",
      " 3   gpa             6194 non-null   float64\n",
      " 4   major           6194 non-null   object \n",
      " 5   race            6194 non-null   object \n",
      " 6   gmat            6194 non-null   float64\n",
      " 7   work_exp        6194 non-null   float64\n",
      " 8   work_industry   6194 non-null   object \n",
      " 9   admission       6194 non-null   object \n",
      "dtypes: bool(1), float64(3), int64(1), object(5)\n",
      "memory usage: 441.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6194 entries, 0 to 6193\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   application_id  6194 non-null   int64  \n",
      " 1   gender          6194 non-null   object \n",
      " 2   international   6194 non-null   bool   \n",
      " 3   gpa             6194 non-null   float64\n",
      " 4   major           6194 non-null   object \n",
      " 5   race            6194 non-null   object \n",
      " 6   gmat            6194 non-null   float64\n",
      " 7   work_exp        6194 non-null   float64\n",
      " 8   work_industry   6194 non-null   object \n",
      " 9   admission       6194 non-null   object \n",
      "dtypes: bool(1), float64(3), int64(1), object(5)\n",
      "memory usage: 441.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race\n",
       "White       0.335486\n",
       "Asian       0.263804\n",
       "Black       0.209881\n",
       "Hispanic    0.134485\n",
       "Other       0.056345\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['race'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admission\n",
       "Deny        0.838553\n",
       "Admit       0.145302\n",
       "Waitlist    0.016145\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['admission'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to remove some redundant values of our dataset.\n",
    "\n",
    "Note that 'gpa' and 'gmat' has some positive correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_id</th>\n",
       "      <th>international</th>\n",
       "      <th>gpa</th>\n",
       "      <th>gmat</th>\n",
       "      <th>work_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>application_id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>0.013872</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>international</th>\n",
       "      <td>0.008045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.028540</td>\n",
       "      <td>-0.014784</td>\n",
       "      <td>-0.010341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpa</th>\n",
       "      <td>0.013872</td>\n",
       "      <td>-0.028540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577539</td>\n",
       "      <td>0.000346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gmat</th>\n",
       "      <td>0.004694</td>\n",
       "      <td>-0.014784</td>\n",
       "      <td>0.577539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_exp</th>\n",
       "      <td>0.003100</td>\n",
       "      <td>-0.010341</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>-0.000999</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                application_id  international       gpa      gmat  work_exp\n",
       "application_id        1.000000       0.008045  0.013872  0.004694  0.003100\n",
       "international         0.008045       1.000000 -0.028540 -0.014784 -0.010341\n",
       "gpa                   0.013872      -0.028540  1.000000  0.577539  0.000346\n",
       "gmat                  0.004694      -0.014784  0.577539  1.000000 -0.000999\n",
       "work_exp              0.003100      -0.010341  0.000346 -0.000999  1.000000"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_columns = ['gender', 'major', 'race', 'work_industry', 'admission']\n",
    "df_numerical = df.drop(columns=string_columns)\n",
    "df_numerical.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null Hypothesis (H‚ÇÄ): There is no linear relationship between GPA and GMAT scores. In other words, the population correlation coefficient \n",
    "œÅ=0.\n",
    "\n",
    "Alternative Hypothesis (H‚ÇÅ): There is a linear relationship between GPA and GMAT scores. This can be expressed as \n",
    "œÅ!=0, meaning the population correlation coefficient is significantly different from 0 (a two-tailed test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation value 0.578\n",
      "P-value 0.000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearson_corr, p_value = pearsonr(df['gmat'].values, df['gpa'].values)\n",
    "print(f\"Pearson correlation value {pearson_corr:.3f}\")\n",
    "print(f\"P-value {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From pearson correlation value as 0.578 indicates a moderate to strong positive linear relationship between GPA and GMAT scores.\n",
    "\n",
    "Since the p-value is less than any typical significance level (e.g., Œ± = 0.05, 0.01), we reject the null hypothesis \n",
    "ùêª‚ÇÄ.\n",
    "\n",
    "Thus, the p-value of 0 tells us that the observed correlation is highly statistically significant, and it is very unlikely that this relationship is due to random chance. Which means that there is significant correlation that can lead to the decision of removing one of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.drop(columns=['gmat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to make our categorical data to numerical data so that we can use this data in sklearn machine learning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder_gender = LabelEncoder()\n",
    "label_encoder_major = LabelEncoder()\n",
    "label_encoder_race = LabelEncoder()\n",
    "label_encoder_work_industry = LabelEncoder()\n",
    "\n",
    "# Transform the categorical variables\n",
    "df_final['gender'] = label_encoder_gender.fit_transform(df_final['gender'])\n",
    "df_final['major'] = label_encoder_major.fit_transform(df_final['major'])\n",
    "df_final['race'] = label_encoder_race.fit_transform(df_final['race'])\n",
    "df_final['work_industry'] = label_encoder_work_industry.fit_transform(df_final['work_industry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>international</th>\n",
       "      <th>gpa</th>\n",
       "      <th>major</th>\n",
       "      <th>race</th>\n",
       "      <th>work_exp</th>\n",
       "      <th>work_industry</th>\n",
       "      <th>admission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3.28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13</td>\n",
       "      <td>Deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Deny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   application_id  gender  international   gpa  major  race  work_exp  \\\n",
       "0               1       0          False  3.30      0     0       3.0   \n",
       "1               2       1          False  3.28      1     1       5.0   \n",
       "2               3       0           True  3.30      0     1       5.0   \n",
       "3               4       1          False  3.47      2     1       6.0   \n",
       "4               5       1          False  3.35      2     2       5.0   \n",
       "\n",
       "   work_industry admission  \n",
       "0              3     Admit  \n",
       "1              6      Deny  \n",
       "2             13     Admit  \n",
       "3             13      Deny  \n",
       "4              1      Deny  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.drop(index=df_final[df_final['admission'] == 'Waitlist'].index)\n",
    "df_final = df_final.drop(columns=['application_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the accuracy of the data with LogisticRegression, RidgeClassifier and KNeighborsClassifier default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: {LogisticRegression(): 0.8518171160609613, RidgeClassifier(): 0.8543962485345838, KNeighborsClassifier(): 0.8710433763188745}\n",
      "\n",
      "Test scores {LogisticRegression(): 0.8414434117003827, RidgeClassifier(): 0.8480043739748496, KNeighborsClassifier(): 0.8326954620010935}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "X = df_final.drop(columns=['admission'])\n",
    "y = df_final['admission']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)\n",
    "\n",
    "accuracy_train = {}\n",
    "accuracy_test = {}\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    RidgeClassifier(),\n",
    "    KNeighborsClassifier()\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    accuracy_train.update({model:train_score})\n",
    "    accuracy_test.update({model:test_score})\n",
    "\n",
    "print(f\"Train scores: {accuracy_train}\\n\\nTest scores {accuracy_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will do a search at the hyperparameter grid for a better solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning hyperparameters for KNeighborsClassifier...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "KNeighborsClassifier Best Parameters: {'n_neighbors': 8, 'weights': 'uniform'}\n",
      "KNeighborsClassifier Best Score: 0.8360680845561047\n",
      "\n",
      "Tuning hyperparameters for LogisticRegression...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "LogisticRegression Best Parameters: {'C': np.float64(2.0684494295802445), 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "LogisticRegression Best Score: 0.8513293218619801\n",
      "\n",
      "Tuning hyperparameters for RidgeClassifier...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/TI/data-science-projects/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lucas/TI/data-science-projects/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/lucas/TI/data-science-projects/venv/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/lucas/TI/data-science-projects/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/lucas/TI/data-science-projects/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/lucas/TI/data-science-projects/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.84656823 0.84640402 0.85132932\n",
      " 0.84656823        nan 0.84640402        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier Best Parameters: {'alpha': np.float64(9.51714306409916)}\n",
      "RidgeClassifier Best Score: 0.8524779389281101\n",
      "\n",
      "Tuning hyperparameters for SVC...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "SVC Best Parameters: {'C': np.float64(6.274815096277165), 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "SVC Best Score: 0.8526418731335141\n",
      "\n",
      "Tuning hyperparameters for DecisionTreeClassifier...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "DecisionTreeClassifier Best Parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 7}\n",
      "DecisionTreeClassifier Best Score: 0.8140777320234761\n",
      "\n",
      "Tuning hyperparameters for RandomForestClassifier...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "RandomForestClassifier Best Parameters: {'max_depth': 10, 'min_samples_split': 9, 'n_estimators': 6}\n",
      "RandomForestClassifier Best Score: 0.8450920092514391\n",
      "\n",
      "Tuning hyperparameters for GradientBoostingClassifier...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "GradientBoostingClassifier Best Parameters: {'learning_rate': np.float64(0.12973169683940733), 'max_depth': 4, 'n_estimators': 3}\n",
      "GradientBoostingClassifier Best Score: 0.8523137353156306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=100),\n",
    "    'RidgeClassifier': RidgeClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "}\n",
    "\n",
    "# Define the hyperparameters and their distributions for each model\n",
    "param_dists = {\n",
    "    'KNeighborsClassifier': {\n",
    "        'n_neighbors': randint(1, 10),\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'C': uniform(0.01, 100),\n",
    "        'penalty': ['l1', 'l2'],  # Note: 'l1' requires the 'liblinear' solver\n",
    "        'solver': ['lbfgs', 'liblinear']\n",
    "    },\n",
    "    'RidgeClassifier': {\n",
    "        'alpha': uniform(0.01, 10)\n",
    "    },\n",
    "    'SVC': {\n",
    "        'C': uniform(0.1, 10),\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'DecisionTreeClassifier': {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': randint(2, 11)\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': randint(1, 10),\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': randint(2, 11)\n",
    "    },\n",
    "    'GradientBoostingClassifier': {\n",
    "        'n_estimators': randint(1, 10),\n",
    "        'learning_rate': uniform(0.01, 0.2),\n",
    "        'max_depth': randint(3, 8)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Loop through models and perform Randomized Search\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTuning hyperparameters for {model_name}...\")\n",
    "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dists[model_name],\n",
    "                                       n_iter=10, scoring='accuracy', cv=5, verbose=1, n_jobs=-1, random_state=42)\n",
    "    random_search.fit(X, y)\n",
    "    \n",
    "    # Best parameters and best score\n",
    "    print(f\"{model_name} Best Parameters: {random_search.best_params_}\")\n",
    "    print(f\"{model_name} Best Score: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above testing, it can be seeing that the best model with the best parameters is SVC with parameters:\n",
    "\n",
    "- 'C' = `np.float64(6.274815096277165)`;\n",
    "- 'gamma' = 'auto';\n",
    "- 'kernel' = 'rbf'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
